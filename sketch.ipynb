{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']\n",
    "PINECONE_ENVIRON = os.environ['PINECONE_ENVIRON']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai_api_key=OPENAI_API_KEY\n",
    "model=\"text-embedding-ada-002\"\n",
    "embed_model=OpenAIEmbeddings(model=model,openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\GPTeach-By-Example\\venv\\Lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexDescription(name='test3', metric='cosine', replicas=1, dimension=1536.0, shards=1, pods=1, pod_type='p1.x1', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRON,\n",
    ")\n",
    "\n",
    "index_name=\"test3\"\n",
    "\n",
    "print(pinecone.describe_index(name=index_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input': 'How do you perform a freeze plug repair?', 'output': '1. Ream hole to original diameter + 0.120 to provide adequate wall thickness.\\n2. Fabricate and install freeze plug.'}, {'input': 'How do you install a repair bushing?', 'output': '1. Ream hole to original diameter + 0.120 to provide adequate wall thickness.\\n2. Fabricate and install repair bushing.'}, {'input': 'Provide repair for an oversized fastener hole.', 'output': '1. Ream hole to original diameter + 0.120 to provide adequate wall thickness.\\n2. Fabricate and install freeze plug.'}, {'input': 'How do you accomplish a doubler repair?', 'output': '1. Trim out damage.\\n2. Fabricate and install doubler with 2 fastener rows.'}, {'input': 'How do you repair damage to the fuselage skin?', 'output': '1. Trim out damage.\\n2. Fabricate and install doubler with 3 fastener rows.'}, {'input': 'How do you repair a large puncture in a panel?', 'output': '1. Trim out damage.\\n2. Fabricate and install doubler with 2 fastener rows.'}, {'input': 'How do you fix a gouge in a composite panel?', 'output': '1. Blend the damage area smooth.\\n2. Fill with epoxy adhesive.'}, {'input': 'How do you fix a puncture in composite panel?', 'output': '1. Remove damage 1/2 inch step per ply.\\n2. Restore plies ply for ply + 1.'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('examples.csv')\n",
    "\n",
    "# Convert DataFrame to dictionary\n",
    "data_dict = df.to_dict(orient='records')\n",
    "print(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n"
     ]
    }
   ],
   "source": [
    "column_names = df.columns.tolist()\n",
    "print(column_names[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input', 'output'] output_parser=None partial_variables={} template='Input: {input}\\nOutput: {output}' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "# examples = data_dict\n",
    "\n",
    "# example_prompt = PromptTemplate(\n",
    "#     input_variables=[column_names[0], column_names[1]],\n",
    "#     template=f\"Input: {{{column_names[0]}}}\\nOutput: {{{column_names[1]}}}\",\n",
    "# )\n",
    "# print(example_prompt)\n",
    "\n",
    "examples = data_dict\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "print(example_prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorstore=<langchain.vectorstores.pinecone.Pinecone object at 0x0000028677E99A90> k=3 example_keys=None input_keys=None\n"
     ]
    }
   ],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # These are the examples it has available to choose from.\n",
    "    examples=examples,\n",
    "    # This is the PromptTemplate being used to format the examples.\n",
    "    example_prompt=example_prompt,\n",
    "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    embeddings=embed_model,\n",
    "    index_name=index_name,\n",
    "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    vectorstore_cls=Pinecone,\n",
    "    k=3,\n",
    ")\n",
    "\n",
    "print(example_selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] output_parser=None partial_variables={} examples=None example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain.vectorstores.pinecone.Pinecone object at 0x0000028677F0D710>, k=3, example_keys=None, input_keys=None) example_prompt=PromptTemplate(input_variables=['input', 'output'], output_parser=None, partial_variables={}, template='Input: {input}\\nOutput: {output}', template_format='f-string', validate_template=True) suffix='Input: {query}\\nOutput: ' example_separator='\\n\\n' prefix='Give step by step repair instructions for every input' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give step by step repair instructions for every input\",\n",
    "    suffix=\"Input: {query}\\nOutput: \", \n",
    "    input_variables=[\"query\"],\n",
    ") \n",
    "\n",
    "print(dynamic_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give step by step repair instructions for every input\n",
      "\n",
      "Input: How do you repair a large puncture in a panel?\n",
      "Output: 1. Trim out damage.\n",
      "2. Fabricate and install doubler with 2 fastener rows.\n",
      "\n",
      "Input: How do you repair a large puncture in a panel?\n",
      "Output: 1. Trim out damage.\n",
      "2. Fabricate and install doubler with 2 fastener rows.\n",
      "\n",
      "Input: How do you repair a large puncture in a panel?\n",
      "Output: 1. Trim out damage.\n",
      "2. Fabricate and install doubler with 2 fastener rows.\n",
      "\n",
      "Input: how do you repair a large puncture?\n",
      "Output: \n"
     ]
    }
   ],
   "source": [
    "# An example with small input, so it selects all examples.\n",
    "print(dynamic_prompt.format(query=\"how do you repair a large puncture?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# openai = ChatOpenAI(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     openai_api_key=OPENAI_API_KEY,\n",
    "#     temperature=0.7\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "openai = OpenAI(\n",
    "    model_name=\"text-davinci-003\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    temperature=0.0,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Ream hole to original diameter + 0.120 to provide adequate wall thickness.\n",
      "2. Fabricate and install freeze plug.\n"
     ]
    }
   ],
   "source": [
    "print(openai(dynamic_prompt.format(query=\"how do you repair an oversized hole?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add an example to an example selector as well.\n",
    "new_example = {\"input\": \"big\", \"output\": \"small\"}\n",
    "dynamic_prompt.example_selector.add_example(new_example)\n",
    "print(dynamic_prompt.format(adjective=\"enthusiastic\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
