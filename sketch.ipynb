{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']\n",
    "PINECONE_ENVIRON = os.environ['PINECONE_ENVIRON']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai_api_key=OPENAI_API_KEY\n",
    "model=\"text-embedding-ada-002\"\n",
    "embed_model=OpenAIEmbeddings(model=model,openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,\n",
    "    environment=PINECONE_ENVIRON,\n",
    ")\n",
    "\n",
    "index_name=\"gpteach\"\n",
    "\n",
    "print(pinecone.describe_index(name=index_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstore_cls=Pinecone.from_existing_index(index_name=index_name,embedding=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('examples.csv')\n",
    "\n",
    "# Convert DataFrame to dictionary\n",
    "data_dict = df.to_dict(orient='records')\n",
    "print(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = df.columns.tolist()\n",
    "print(column_names[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = data_dict\n",
    "\n",
    "# example_prompt = PromptTemplate(\n",
    "#     input_variables=[column_names[0], column_names[1]],\n",
    "#     template=f\"Input: {{{column_names[0]}}}\\nOutput: {{{column_names[1]}}}\",\n",
    "# )\n",
    "# print(example_prompt)\n",
    "\n",
    "examples = data_dict\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "print(example_prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # These are the examples it has available to choose from.\n",
    "    examples=examples,\n",
    "    # This is the PromptTemplate being used to format the examples.\n",
    "    example_prompt=example_prompt,\n",
    "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    embeddings=embed_model,\n",
    "    index_name=index_name,\n",
    "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    vectorstore_cls=Pinecone,\n",
    "    k=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give step by step repair instructions for every input\",\n",
    "    suffix=\"Input: {query}\\nOutput: \", \n",
    "    input_variables=[\"query\"],\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example with small input, so it selects all examples.\n",
    "print(dynamic_prompt.format(query=\"how do you repair a large puncture?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# openai = ChatOpenAI(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     openai_api_key=OPENAI_API_KEY,\n",
    "#     temperature=0.7\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "openai = OpenAI(\n",
    "    model_name=\"text-davinci-003\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(openai(dynamic_prompt.format(query=\"how do you repair an oversized hole?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add an example to an example selector as well.\n",
    "new_example = {\"input\": \"big\", \"output\": \"small\"}\n",
    "dynamic_prompt.example_selector.add_example(new_example)\n",
    "print(dynamic_prompt.format(adjective=\"enthusiastic\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
